{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1cbc05",
   "metadata": {},
   "source": [
    "# D-GCAN Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a486bf",
   "metadata": {},
   "source": [
    "In this tutorial, we take a deep dive into D-GCAN and show how it builds a drug-likeness prediction model from scratch.\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cacf2e",
   "metadata": {},
   "source": [
    "## Part I: Overview of D-GCAN and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a44a94",
   "metadata": {},
   "source": [
    "The drug-likeness has been widely used as a criterion to distinguish drug-like molecules from non-drugs. Developing reliable computational methods to predict drug-likeness of compounds is crucial to triage unpromising molecules and accelerate the drug discovery process.In this study, a deep learning method was developed to predict drug-likeness based on the graph convo-lutional attention network (D-GCAN) directly from molecular structures. The model combined the ad-vantages of graph convolution and attention mechanism. Results showed that the D-GCAN outper-formed other state-of-the-art models for drug-likeness prediction. Molecular graph was used as encoding method for drug-likeness prediction.\n",
    "\n",
    "A dataset with enough drugs and non-drugs is the prerequisite to train accurate deep neural network models for prediction of drug-likeness.In this study, D-GCAN model was trained on the dataset released by Beker, which consists of drug and non-drug sets (abbrevi-ated as: Drugs and Non-drugs). The Drugs set includes 2136 FDA small-molecule drugs assembled from Drugbank. The Non-drugs was chosen from ZINC15. Compounds with a maximum fingerprint-based Tanimoto similarity to drugs above 0.85 were removed, and standard binary classification was used to itera-tively refine the set of reliable negative set. Since the negative set is much larger than the positive set, it was randomly down-sampled to create a balanced dataset for model training. The dataset was randomly divided into training, validation, and test sets at ratio 8:1:1. In addition, two additional datasets, the non-US dataset and the bRo5 dataset, were used to test the performance of the model. The non-US dataset composes of 1281 word-wide drugs from Drugbank and an equal size of non-drugs from ZINC15. The bRo5 dataset includes 135 FDA and non-US drugs beyond Ro5 space (bRo5). The GDB-13 data-base was used to test the ability of D-GCAN in screening large-scale data. It consists of about 977 million drug-like small molecules according to Lipinskiâ€™s rule. All molecules contain up to 13 heavy atoms , and they were stored in the canonical SMILES. All the independent test datasets and validation dataset were not used in the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597ea85",
   "metadata": {},
   "source": [
    "## Part II: To train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e8ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcca4e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code uses a GPU!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Just a moment......\n",
      "----------------------------------------------------------------------------------------------------\n",
      "../dataset/data_train.txt\n",
      "../dataset/data_test.txt\n",
      "The preprocess has finished!\n",
      "# of training data samples: 3802\n",
      "# of test data samples: 428\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Creating a model.\n",
      "# of model parameters: 311698\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Start training.\n",
      "The result is saved in the output directory every epoch!\n",
      "The training will finish in about 0 hours 21 minutes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch\tTime(sec)\tLoss_train\tLoss_test\tAUC_train\tAUC_test\n",
      "1\t9.334350300000011\t318.02376973629\t33.23613902926445\t0.6330387783115992\t0.5116822429906542\n",
      "2\t16.232699300000007\t275.59704649448395\t28.36697283387184\t0.7726390395642837\t0.5233644859813084\n",
      "3\t22.533227600000004\t258.0953543186188\t26.692712754011154\t0.8227923594659818\t0.530373831775701\n",
      "4\t30.035969300000005\t244.29262351989746\t25.99587020277977\t0.8555440089003034\t0.5934579439252337\n",
      "5\t36.20996820000002\t235.61571648716927\t26.206634640693665\t0.8711811167445258\t0.544392523364486\n",
      "6\t42.15839070000001\t235.10905063152313\t24.74921104311943\t0.8782201330617486\t0.5771028037383178\n",
      "7\t48.091756000000004\t230.60763642191887\t24.482909947633743\t0.8858224754798858\t0.6308411214953271\n",
      "8\t53.9427063\t225.9473716020584\t25.168260991573334\t0.894445889698231\t0.5794392523364486\n",
      "9\t59.887297399999994\t220.88472372293472\t23.143073588609695\t0.9038094737308211\t0.6845794392523364\n",
      "10\t65.88160690000001\t220.29008296132088\t23.10640263557434\t0.9080117951159034\t0.6542056074766355\n",
      "11\t71.7950055\t220.04156962037086\t23.67304638028145\t0.905873895764607\t0.7289719626168224\n",
      "12\t77.81804110000002\t214.85031658411026\t23.34747040271759\t0.9159177330794608\t0.8200934579439252\n",
      "13\t83.67658890000001\t212.33444252610207\t23.14932319521904\t0.9178444716275156\t0.735981308411215\n",
      "14\t89.6064955\t211.54040449857712\t22.778073489665985\t0.9219235005645715\t0.7593457943925234\n",
      "15\t95.5943882\t208.26400744915009\t22.901916056871414\t0.9267551530985012\t0.7663551401869159\n",
      "16\t101.6206004\t209.3945328295231\t23.913705557584763\t0.9246417461863752\t0.6915887850467289\n",
      "17\t107.65320110000002\t206.03158766031265\t23.282782286405563\t0.930114906901056\t0.7313084112149533\n",
      "18\t113.61952920000002\t207.53857171535492\t22.225304275751114\t0.9226543992295261\t0.8037383177570093\n",
      "19\t120.54484979999998\t204.79183167219162\t23.475462794303894\t0.926265719441185\t0.735981308411215\n",
      "20\t126.48899880000002\t205.36031165719032\t22.78501933813095\t0.9291473863661524\t0.8107476635514018\n",
      "21\t132.3617932\t202.3321330845356\t23.385528802871704\t0.9302150906635376\t0.7897196261682243\n",
      "22\t138.31940950000003\t202.55410113930702\t23.08760157227516\t0.9293607611751943\t0.7686915887850467\n",
      "23\t144.17849070000003\t198.95897144079208\t22.36356022953987\t0.9377836694932141\t0.8294392523364486\n",
      "24\t150.04248400000003\t197.13710144162178\t23.3654263317585\t0.9351247869019417\t0.8084112149532711\n",
      "25\t155.89731129999998\t256.36723348498344\t22.31619429588318\t0.7880461675559591\t0.8411214953271028\n",
      "26\t161.73105990000002\t199.1333883702755\t22.19395723938942\t0.9381437221865521\t0.8200934579439252\n",
      "27\t167.57376660000003\t195.61116680502892\t21.885735362768173\t0.9357744592290832\t0.8621495327102804\n",
      "28\t173.4351409\t196.21020331978798\t21.808892458677292\t0.937718217946731\t0.8808411214953271\n",
      "29\t179.35259220000003\t196.93134278059006\t22.267054110765457\t0.9385652135408595\t0.8481308411214953\n",
      "30\t185.28482499999998\t195.89555063843727\t22.040870487689972\t0.9386104622844113\t0.8434579439252337\n",
      "31\t191.16947059999998\t194.0237057507038\t22.781775504350662\t0.9417760754533178\t0.8387850467289719\n",
      "32\t197.0987102\t193.68072113394737\t22.449314266443253\t0.9423293001527663\t0.8294392523364486\n",
      "33\t203.01129849999998\t192.5338954925537\t22.377066612243652\t0.9452480516748955\t0.8621495327102804\n",
      "34\t209.6004434\t192.58278796076775\t23.285291463136673\t0.9402174153696283\t0.8714953271028038\n",
      "35\t216.03077720000002\t196.01435166597366\t24.061037868261337\t0.9359749651294087\t0.8014018691588785\n",
      "36\t222.4218536\t193.9636361002922\t22.313345968723297\t0.936061864857086\t0.8434579439252337\n",
      "37\t228.7779303\t192.51033294200897\t22.285043627023697\t0.9435566896185268\t0.8317757009345794\n",
      "38\t235.1833634\t188.01407945156097\t22.830698162317276\t0.94882975955897\t0.8014018691588785\n",
      "39\t241.73452799999998\t193.91294729709625\t22.711496233940125\t0.9402640478668054\t0.8294392523364486\n",
      "40\t248.1350879\t192.2110168337822\t21.79123494029045\t0.9453036785706378\t0.8785046728971962\n",
      "41\t254.51809260000002\t189.3926584124565\t23.183754086494446\t0.9464263178869528\t0.822429906542056\n",
      "42\t260.67076799999995\t197.67854461073875\t24.210958123207092\t0.9356472922709057\t0.8714953271028038\n",
      "43\t266.8244926\t195.8016073703766\t22.462971657514572\t0.9351026468439347\t0.8107476635514018\n",
      "44\t273.0223882\t191.97943636775017\t23.224840223789215\t0.940738813735692\t0.8247663551401869\n",
      "45\t279.0850431\t190.848837941885\t22.82283341884613\t0.9461044567936768\t0.8060747663551402\n",
      "46\t285.1555958\t190.04618108272552\t22.433310955762863\t0.9440021199105542\t0.7967289719626168\n",
      "47\t291.1587971\t190.5216095149517\t22.426137387752533\t0.9457633615250072\t0.822429906542056\n",
      "48\t297.2169235\t185.92078268527985\t22.22221177816391\t0.9480603925432284\t0.8247663551401869\n",
      "49\t303.3877255\t187.782156676054\t22.887968957424164\t0.94423528239644\t0.8364485981308412\n",
      "50\t309.40409650000004\t187.28414443135262\t21.483285009860992\t0.9458896982310093\t0.8714953271028038\n",
      "51\t315.44450670000003\t185.18417713046074\t21.38184556365013\t0.9481489527752565\t0.8785046728971962\n",
      "52\t321.7301946\t182.16105404496193\t24.673764526844025\t0.9509743009276684\t0.7920560747663551\n",
      "53\t327.84551209999995\t188.7527618408203\t23.513393253087997\t0.9457229559191445\t0.8154205607476636\n",
      "54\t334.0279252\t185.709531635046\t21.631520986557007\t0.9463949066796555\t0.8808411214953271\n",
      "55\t340.16017209999995\t185.12931755185127\t22.429152816534042\t0.944120984346979\t0.8294392523364486\n",
      "56\t346.29319970000006\t182.88407680392265\t21.58257967233658\t0.9498509697345405\t0.8761682242990654\n",
      "57\t357.14253529999996\t182.04424741864204\t21.475889027118683\t0.9525705991099698\t0.8808411214953271\n",
      "58\t363.8143368\t182.934487760067\t21.883195608854294\t0.949658766355968\t0.8714953271028038\n",
      "59\t370.1603794\t184.17358297109604\t21.290808767080307\t0.9471534804171187\t0.883177570093458\n",
      "60\t376.4684089\t181.42354640364647\t21.597694754600525\t0.949361674452587\t0.9042056074766355\n",
      "61\t382.88365710000005\t187.25566163659096\t21.6785786151886\t0.9452393340270551\t0.866822429906542\n",
      "62\t389.3225355000001\t181.59250125288963\t21.666670441627502\t0.9521657127991676\t0.8598130841121495\n",
      "63\t396.0132287\t179.8839019536972\t22.01644539833069\t0.9538880709367459\t0.852803738317757\n",
      "64\t402.58914460000005\t182.93770709633827\t22.33838379383087\t0.9484886642903003\t0.8504672897196262\n",
      "65\t409.2413564000001\t181.58496183156967\t22.23741576075554\t0.950153319901698\t0.8785046728971962\n",
      "66\t415.7737618\t182.49673774838448\t21.934344708919525\t0.9507491642128103\t0.8785046728971962\n",
      "67\t422.29757770000003\t180.1727076768875\t22.335491836071014\t0.9534794484911551\t0.852803738317757\n",
      "68\t428.7057098\t182.3468733727932\t21.559545934200287\t0.953210031660283\t0.8855140186915887\n",
      "69\t435.1430776000001\t177.6970148384571\t21.813909739255905\t0.9542144984169858\t0.8785046728971962\n",
      "70\t441.59579740000004\t179.4230616092682\t21.47458705306053\t0.9503143888236987\t0.8925233644859814\n",
      "71\t447.9559312\t187.4236896932125\t21.997405976057053\t0.9434714503952\t0.8714953271028038\n",
      "72\t454.36015280000004\t185.64457353949547\t21.80859535932541\t0.9493346912568912\t0.8995327102803738\n",
      "73\t460.8502926\t183.28448390960693\t22.7678345143795\t0.942662231275046\t0.8504672897196262\n",
      "74\t467.7673221\t181.35295176506042\t21.99883532524109\t0.9524445391546925\t0.8317757009345794\n",
      "75\t474.20574880000004\t180.42559936642647\t22.20555028319359\t0.9545189242145815\t0.8621495327102804\n",
      "76\t480.7348668000001\t177.4391260445118\t21.684407979249954\t0.9532330019704651\t0.8878504672897196\n",
      "77\t488.22190610000007\t187.34195244312286\t22.080274641513824\t0.9482340536232203\t0.8738317757009346\n",
      "78\t498.7163915\t184.663908213377\t22.014076620340347\t0.9470819403546837\t0.8691588785046729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\t507.72747260000006\t178.98830798268318\t21.47413921356201\t0.9541025527486882\t0.8598130841121495\n",
      "80\t516.8672275\t178.3373854458332\t21.658688694238663\t0.9525628500896672\t0.8901869158878505\n",
      "81\t526.2272582\t176.8597036600113\t22.024581998586655\t0.9535130737042532\t0.8644859813084113\n",
      "82\t537.2631751\t177.2030012011528\t21.766023725271225\t0.957143212965218\t0.8691588785046729\n",
      "83\t548.0884053000001\t176.38141465187073\t21.79708757996559\t0.9572966712422787\t0.8714953271028038\n",
      "84\t559.8119843000001\t174.46399101614952\t21.843281388282776\t0.956292066110213\t0.8574766355140186\n",
      "85\t569.1060591\t175.65917918086052\t21.409487038850784\t0.9559244027719352\t0.9018691588785047\n",
      "86\t576.5913633\t176.77976202964783\t21.49503728747368\t0.9538743717758542\t0.8785046728971962\n",
      "87\t584.3266782000001\t179.85141596198082\t21.427332252264023\t0.9514658102154229\t0.9018691588785047\n",
      "88\t595.5166383000001\t178.52282038331032\t21.403560250997543\t0.9539066132353267\t0.8644859813084113\n",
      "89\t605.9234084000001\t177.05544209480286\t21.411171078681946\t0.9535158412115041\t0.9042056074766355\n",
      "90\t613.9635365\t176.31908676028252\t21.366370409727097\t0.955243734363584\t0.8878504672897196\n",
      "91\t623.9597695\t176.20382365584373\t21.893729746341705\t0.9558952055704386\t0.8761682242990654\n",
      "92\t634.0385619\t175.1233125925064\t22.482848435640335\t0.9574447328802002\t0.8621495327102804\n",
      "93\t644.2752579\t176.93210792541504\t21.549375027418137\t0.9527253027652932\t0.8948598130841121\n",
      "94\t652.8900821000001\t173.00296890735626\t21.5932075381279\t0.9579943598202227\t0.8855140186915887\n",
      "95\t667.6088093000001\t179.9282302260399\t23.50808882713318\t0.9537645017379945\t0.8341121495327103\n",
      "96\t676.2838057\t174.56020081043243\t22.648311734199524\t0.9556187315960767\t0.8714953271028038\n",
      "97\t685.9453472\t176.7171704173088\t21.891200184822083\t0.9524900646489693\t0.897196261682243\n",
      "98\t694.2790274\t178.38612964749336\t22.245244562625885\t0.9540746009254544\t0.8808411214953271\n",
      "99\t702.7636145\t177.73075929284096\t24.06598174571991\t0.9527554685943277\t0.897196261682243\n",
      "100\t713.3440201000001\t177.71725061535835\t23.09346652030945\t0.9563492151349435\t0.8434579439252337\n",
      "101\t722.6864448\t173.766254901886\t22.383565932512283\t0.9588301470099851\t0.8785046728971962\n",
      "102\t731.0422685000001\t173.67894527316093\t21.84225881099701\t0.9581018774769188\t0.8855140186915887\n",
      "103\t739.0269975\t175.92625331878662\t22.260210156440735\t0.956732791639914\t0.8691588785046729\n",
      "104\t746.7896567\t174.88757956027985\t21.68474268913269\t0.95813674806828\t0.8901869158878505\n",
      "105\t754.1008847\t176.1177335381508\t22.008816480636597\t0.9573001306263422\t0.8785046728971962\n",
      "106\t761.2548227000001\t174.49301874637604\t21.83292892575264\t0.9588928310492174\t0.897196261682243\n",
      "107\t768.4392893\t172.7093889117241\t21.64242872595787\t0.9596258053446101\t0.8878504672897196\n",
      "108\t775.9572361\t177.16424638032913\t21.55477637052536\t0.9525133117098767\t0.9065420560747663\n",
      "109\t784.4066813000001\t178.4102607667446\t21.33096119761467\t0.9554701164567051\t0.9042056074766355\n",
      "110\t794.4927042\t174.0306807756424\t21.91256058216095\t0.9572584796422166\t0.8714953271028038\n",
      "111\t802.6228819\t174.55561447143555\t21.62583690881729\t0.9593071268846725\t0.9088785046728972\n",
      "112\t810.7530621000001\t172.49658674001694\t22.11896824836731\t0.9582462029800518\t0.8901869158878505\n",
      "113\t818.6795158\t173.48215851187706\t21.262643307447433\t0.9584646976775077\t0.897196261682243\n",
      "114\t827.9049124000001\t174.29942700266838\t21.171885669231415\t0.9568379569154472\t0.9088785046728972\n",
      "115\t837.2002482\t171.870591878891\t21.214154481887817\t0.9590825436712644\t0.9158878504672897\n",
      "116\t845.4472041\t176.74994710087776\t22.71759131550789\t0.9544714614652291\t0.8995327102803738\n",
      "117\t853.6806366000001\t184.73798117041588\t21.845041394233704\t0.9432161478513075\t0.8995327102803738\n",
      "118\t868.1707754\t177.2356958091259\t21.59891825914383\t0.9571596796333606\t0.9112149532710281\n",
      "119\t875.8412158\t176.63044354319572\t21.46969723701477\t0.9547083600859034\t0.9088785046728972\n",
      "120\t884.2734249\t172.92364439368248\t21.97585704922676\t0.9586079161777404\t0.9065420560747663\n",
      "121\t892.1201223\t180.26964315772057\t21.951832473278046\t0.948673395399296\t0.9018691588785047\n",
      "122\t899.5396582999999\t173.81644931435585\t21.459405571222305\t0.9592527453671928\t0.8925233644859814\n",
      "123\t906.7295165\t176.33700492978096\t21.565876573324203\t0.9538397779352181\t0.8761682242990654\n",
      "124\t914.7522263999999\t172.69166892766953\t21.18627032637596\t0.9598193924768083\t0.9112149532710281\n",
      "125\t923.6481627000001\t171.38375091552734\t21.528594940900803\t0.9606258440897115\t0.8995327102803738\n",
      "126\t932.1785648\t171.18208953738213\t22.116858184337616\t0.9604675426749618\t0.8785046728971962\n",
      "127\t939.5199154\t171.14211875200272\t22.178175538778305\t0.9611412923151859\t0.883177570093458\n",
      "128\t946.4239123\t169.92953234910965\t21.887178242206573\t0.9611555449775278\t0.8808411214953271\n",
      "129\t954.5059573000001\t174.96560329198837\t22.6447791159153\t0.9555907797728429\t0.8761682242990654\n",
      "130\t961.8763295000001\t178.70918104052544\t22.300085812807083\t0.9529475335975381\t0.8808411214953271\n",
      "131\t969.1789554\t174.0145247578621\t22.113102048635483\t0.9579599043549494\t0.8808411214953271\n",
      "132\t976.3019077000001\t172.59970355033875\t21.501632899045944\t0.9596043571634159\t0.9018691588785047\n",
      "133\t984.5187846000001\t172.19679167866707\t22.107417851686478\t0.9594648747979719\t0.8808411214953271\n",
      "134\t993.8344443000001\t173.3250037431717\t23.72211918234825\t0.9588380344056502\t0.8341121495327103\n",
      "135\t1002.1266977\t173.15374860167503\t22.544156223535538\t0.9600561527221201\t0.8738317757009346\n",
      "136\t1009.9465580000001\t171.82129180431366\t22.224039256572723\t0.9606888048796689\t0.8738317757009346\n",
      "137\t1018.5052494000001\t171.67953670024872\t22.0196373462677\t0.9615298503332077\t0.8901869158878505\n",
      "138\t1028.1396465\t172.37993958592415\t22.44371086359024\t0.9589339285318929\t0.8808411214953271\n",
      "139\t1037.3752773\t174.99391075968742\t21.463502824306488\t0.9590761784045874\t0.9018691588785047\n",
      "140\t1046.0815085\t174.17848363518715\t21.192844033241272\t0.959691256891093\t0.9042056074766355\n",
      "auc: 0.9042056074766356\n",
      "bacc: 0.9042056074766356\n",
      "pre: 0.9303482587064676\n",
      "rec: 0.8738317757009346\n",
      "f1: 0.9012048192771085\n",
      "mcc: 0.8099069874057296\n",
      "sp: 0.9345794392523364\n",
      "q_: 0.8810572687224669\n",
      "acc: 0.9042056074766355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tes = train.train('../dataset/data_test.txt', #test set   \n",
    "    radius = 1,        #hops of radius subgraph: 1, 2 \n",
    "    dim = 52,          #dimension of graph convolution layers\n",
    "    layer_hidden = 4,  #Number of graph convolution layers\n",
    "    layer_output = 10, #Number of dense layers\n",
    "    dropout = 0.45,    #drop out rate :0-1\n",
    "    batch_train = 8,   # batch of training set\n",
    "    batch_test = 8,    #batch of test set\n",
    "    lr =3e-4,          #learning rate: 1e-5,1e-4,3e-4, 5e-4, 1e-3, 3e-3,5e-3\n",
    "    lr_decay = 0.85,   #Learning rate decay:0.5, 0.75, 0.85, 0.9\n",
    "    decay_interval = 25,#Number of iterations for learning rate decay:10,25,30,50\n",
    "    iteration = 140,    #Number of iterations \n",
    "    N = 5000,           #length of embedding: 2000,3000,5000,7000 \n",
    "    dataset_train='../dataset/data_train.txt') #training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a50302",
   "metadata": {},
   "source": [
    "## Part III: To test the performance of the D-GCAN on independent model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581857d7",
   "metadata": {},
   "source": [
    "We have provided the trained model. And it can be used directly as follow:\n",
    "\n",
    "We test the trained model on bRo5 dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ee166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68722dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d307e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code uses a GPU!\n",
      "../dataset/bRo5.txt\n",
      "SMILESis error\n",
      "bacc: 0.9580740740740741\n",
      "pre: 0.9696969696969697\n",
      "rec: 0.9481481481481482\n",
      "f1: 0.9588014981273408\n",
      "mcc: 0.9155786319049269\n",
      "sp: 0.968\n",
      "q_: 0.9453125\n",
      "acc: 0.9576923076923077\n"
     ]
    }
   ],
   "source": [
    "test = predict.predict('../dataset/bRo5.txt',\n",
    "    radius = 1,\n",
    "    property = True,   #True if drug-likeness is known \n",
    "    dim = 52 ,\n",
    "    layer_hidden = 4,\n",
    "    layer_output = 10,\n",
    "    dropout = 0.45,\n",
    "    batch_train = 8,\n",
    "    batch_test = 8,\n",
    "    lr = 3e-4,\n",
    "    lr_decay = 0.85,\n",
    "    decay_interval = 25 ,\n",
    "    iteration = 140,\n",
    "    N = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe34a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feedbacks would also be appreciated and you can send me an email (jinyusun@csu.edu.cn)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
